{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a151a4-c4af-4516-bb54-45dd812ac3c9",
   "metadata": {},
   "source": [
    "# Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f3e17-7034-44ea-bea3-9b2ff46b60f1",
   "metadata": {},
   "source": [
    "Link: https://huggingface.co/learn/llm-course/chapter1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cacebd-2f0f-4bad-b4f2-b1b3f16bef20",
   "metadata": {},
   "source": [
    "## Transformers, what can they do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8030b49-95ca-457d-b872-c77fb3ec078c",
   "metadata": {},
   "source": [
    "### Working with pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c41415-574c-4d93-878a-d517d4250c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "# To explicitly specify the model\n",
    "# classifier = pipeline(\n",
    "#    \"sentiment-analysis\",\n",
    "#    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#)\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842ab75-68d9-4ed6-8366-f0e92183c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\", \"That was so good!\", \"It could go both ways\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d453b030-fe8f-4578-918c-82e5bc1b4416",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002e33b-b481-4a1e-a143-69bf8d721e6e",
   "metadata": {},
   "source": [
    "First, we define a downloadIfNotCached function. This will only be done once here. Thereafter, all cells for local cached version will use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72654571-f340-4e1f-a98c-50bb7b789471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a downloadIfNotCached function\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "def downloadIfNotCached(modelname: str, base_dir: str = \"./model_store\") -> str:\n",
    "    \"\"\"\n",
    "    Download a Hugging Face model repo locally if not already cached.\n",
    "\n",
    "    Returns the local path to the model directory.\n",
    "    \"\"\"\n",
    "    model_dir = Path(base_dir) / Path(modelname)\n",
    "\n",
    "    if model_dir.exists():\n",
    "        return str(model_dir)\n",
    "\n",
    "    snapshot_download(\n",
    "        repo_id=modelname,\n",
    "        local_dir=model_dir,\n",
    "        local_dir_use_symlinks=False,\n",
    "    )\n",
    "\n",
    "    return str(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fe5f5-6af3-494a-b68a-d555935b2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\", \"That was so good!\", \"It could go both ways\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9104390-faef-45a9-9782-a1544bb0eee5",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f1448-d21b-47e3-9cd9-81526f79f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963f482-ff4c-4aa5-a040-011a20011f62",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc8e5e-89a8-4d55-a4fb-d7e6be9dbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"facebook/bart-large-mnli\")\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87f0ff-d912-4b55-9ce1-4d88f4de0800",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc81527-8b94-4a52-b794-8a46218d0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd6e7d-f597-4fe4-ba27-4e97fa33b099",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015ae09-1589-4ef8-96ab-4688e65c5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"openai-community/gpt2\")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "generator(\"In this course, we will teach you how to\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea7882-db2a-4e8f-88a1-6bff7d114fc6",
   "metadata": {},
   "source": [
    "### Using any model from the Hub in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36ce29-c22e-44c1-ac75-64260d86c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-135M\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15e96e-0900-44f4-b68b-1cc7af9be785",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3767ee6-25b5-4236-9661-9afc00f41fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# model_path = downloadIfNotCached(\"HuggingFaceTB/SmolLM2-360M\")\n",
    "model_path = downloadIfNotCached(\"HuggingFaceTB/SmolLM2-135M\")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5c661-9e74-488e-9eb6-4e11ec494f2c",
   "metadata": {},
   "source": [
    "### Mask Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f38ee-4a15-4e63-8433-955a6ce4c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7108f-c32f-4cdf-94b2-bd9b78fb6eb8",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b1601-fb71-4020-ab85-af3f2c63ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"distilbert/distilroberta-base\")\n",
    "\n",
    "unmasker = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "unmasker(\n",
    "    \"This course will teach you all about <mask> models.\",\n",
    "    top_k=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5c188-d00b-415d-88b0-fca16a56392a",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172d713-9451-4c49-87e6-754210a46976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf6e7c-a3a5-46bb-afd0-f6e278c21ce2",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7af514-0ec3-4b06-b26d-0ec97b75958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\n",
    "    \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    ")\n",
    "\n",
    "ner = pipeline(\n",
    "    \"ner\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    grouped_entities=True,\n",
    ")\n",
    "\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5cf38f-1999-42fc-a8fb-5ef197525c16",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec0649-9788-4cea-afe2-027c9462179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aedb0f-c7d2-4aee-990d-4e0c76b7d392",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47521b66-4734-41f2-a1ef-fa31e055e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\n",
    "    \"distilbert/distilbert-base-cased-distilled-squad\"\n",
    ")\n",
    "\n",
    "question_answerer = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2670501-88e9-4db2-8501-086dd43987b9",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4792c18-252b-49cc-a387-a54d39da0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04c041-2c5f-4039-acd8-10a5b2a2cab7",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51383d03-f23e-4613-8f73-4f5d38828265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"facebook/bart-large-cnn\"\n",
    "model_path = downloadIfNotCached(model_id)\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "text = \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    "\n",
    "summarizer(text, max_length=60, min_length=20, do_sample=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039a017-8202-4070-a130-272fdf72e901",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c637f-66e8-4c06-b54f-4f2010bc4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67e1b5-8dfb-4cfa-8b45-bbd0d7ab280e",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2b62e-37f7-479a-aca4-bfa20fb35f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "translator(\"Ce cours est produit par Hugging Face.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3d42a-08b2-4c5c-bc96-c1596ab26932",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea4f78-9f72-493f-9d77-e070eea47a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_classifier = pipeline(\n",
    "    task=\"image-classification\", model=\"google/vit-base-patch16-224\"\n",
    ")\n",
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48dea5-2a4c-4af4-bf70-30133c38c800",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331db37-643c-4fd4-9848-d75258ee05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"google/vit-base-patch16-224\")\n",
    "\n",
    "image_classifier = pipeline(\n",
    "    task=\"image-classification\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4c547-f266-483e-a908-13bf121ba325",
   "metadata": {},
   "source": [
    "### Automatic speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5cffc-8f80-4d71-959e-9ca6d0b98f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\n",
    "    task=\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\"\n",
    ")\n",
    "result = transcriber(\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2a667-9e7b-41bf-981c-5771e8db1480",
   "metadata": {},
   "source": [
    "#### Local Cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07121dec-5e16-4ec3-ace9-fb908e5c578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = downloadIfNotCached(\"openai/whisper-large-v3\")\n",
    "\n",
    "transcriber = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    ")\n",
    "\n",
    "result = transcriber(\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
